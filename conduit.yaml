# Conduit Configuration
# See docs/configuration.md for detailed documentation
# Last updated: 2025-11-25

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Default models for routing. Update these when new model versions release.
# Check AGENTS.md "Model Reference" section for current best models.
#
# Sources (Nov 2025):
# - OpenAI GPT-5.1: https://openai.com/index/gpt-5-1-for-developers/
# - Anthropic Claude Opus 4.5: https://www.anthropic.com/news/claude-opus-4-5
# - Google Gemini 3: https://blog.google/products/gemini/gemini-3/

models:
  # Default routing pool (used when no specific models requested)
  # Order matters: first model is primary fallback
  default:
    - o4-mini                    # OpenAI fast reasoning (cost-effective)
    - gpt-5.1                    # OpenAI flagship (76.3% SWE-bench)
    - claude-sonnet-4-5-20241124 # Anthropic balanced
    - gemini-2.5-flash           # Google fast

  # Model for Arbiter LLM-as-judge evaluation (cheap, fast preferred)
  arbiter: o4-mini

  # Global fallback when requested model is unknown
  fallback: o4-mini

# Provider-specific fallbacks for unknown model IDs
# When we see a model ID we don't recognize, use these based on provider pattern
provider_fallbacks:
  openai: o4-mini
  anthropic: claude-haiku-4-5-20241124
  google: gemini-2.5-flash
  meta: llama-4-scout
  mistral: mistral-small-latest
  default: o4-mini               # When provider can't be determined

# =============================================================================
# FALLBACK PRICING (per 1M tokens, USD)
# =============================================================================
# Used when database pricing unavailable. Update monthly from provider sites.
# Source: https://artificialanalysis.ai/leaderboards/providers

pricing:
  # OpenAI models (Nov 2025)
  o4-mini:
    input: 1.10
    output: 4.40
  gpt-5.1:
    input: 2.00
    output: 8.00
  gpt-5.1-codex-mini:
    input: 0.50
    output: 2.00
  # Legacy OpenAI (still supported)
  gpt-4o-mini:
    input: 0.15
    output: 0.60
  gpt-4o:
    input: 2.50
    output: 10.00

  # Anthropic models (Nov 2025 - Claude 4.5 series)
  claude-opus-4-5-20241124:
    input: 5.00
    output: 25.00
  claude-sonnet-4-5-20241124:
    input: 3.00
    output: 15.00
  claude-haiku-4-5-20241124:
    input: 0.80
    output: 4.00

  # Google models (Nov 2025 - Gemini 3 series)
  gemini-3.0-pro:
    input: 1.25
    output: 5.00
  gemini-2.5-flash:
    input: 0.075
    output: 0.30
  gemini-2.5-pro:
    input: 1.25
    output: 5.00

  # Meta models (via Groq/Together)
  llama-4-maverick:
    input: 0.50
    output: 0.50
  llama-4-scout:
    input: 0.11
    output: 0.11

  # Mistral models
  mistral-large-latest:
    input: 2.00
    output: 6.00
  mistral-small-latest:
    input: 0.20
    output: 0.60

  # Conservative default for unknown models
  _default:
    input: 1.00
    output: 3.00

# =============================================================================
# ROUTING CONFIGURATION
# =============================================================================

routing:
  # Default optimization strategy
  # Options: balanced, quality, cost, speed
  default_optimization: balanced

  # Reward weight presets for routing decisions
  # Each preset balances quality, cost, and latency differently
  # Weights must sum to 1.0
  presets:
    balanced:
      quality: 0.7    # Prioritize quality
      cost: 0.2       # Moderate cost concern
      latency: 0.1    # Low latency concern

    quality:
      quality: 0.8    # Maximize quality
      cost: 0.1       # Minimal cost concern
      latency: 0.1    # Minimal latency concern

    cost:
      quality: 0.4    # Acceptable quality
      cost: 0.5       # Minimize cost
      latency: 0.1    # Low latency concern

    speed:
      quality: 0.4    # Acceptable quality
      cost: 0.1       # Low cost concern
      latency: 0.5    # Minimize latency
