# Conduit Configuration
# See docs/configuration.md for detailed documentation

routing:
  # Default optimization strategy
  # Options: balanced, quality, cost, speed
  default_optimization: balanced

  # Reward weight presets for routing decisions
  # Each preset balances quality, cost, and latency differently
  # Weights must sum to 1.0
  presets:
    balanced:
      quality: 0.7    # Prioritize quality
      cost: 0.2       # Moderate cost concern
      latency: 0.1    # Low latency concern

    quality:
      quality: 0.8    # Maximize quality
      cost: 0.1       # Minimal cost concern
      latency: 0.1    # Minimal latency concern

    cost:
      quality: 0.4    # Acceptable quality
      cost: 0.5       # Minimize cost
      latency: 0.1    # Low latency concern

    speed:
      quality: 0.4    # Acceptable quality
      cost: 0.1       # Low cost concern
      latency: 0.5    # Minimize latency

# Context-specific priors for Thompson Sampling cold start optimization.
# These priors help the bandit algorithm make better routing decisions before
# it has collected enough data to learn model performance empirically.
#
# How it works:
#   - Quality scores (0.0-1.0) represent expected success rate for each context
#   - Scores are converted to Beta(alpha, beta) distribution parameters
#   - Higher score = more confident the model performs well in that context
#   - Prior strength is ~10,000 samples, so real observations gradually override
#
# Example: claude-sonnet-4.5: 0.92 for "code" means we expect 92% quality
# on coding tasks, giving it a head start until real feedback proves otherwise.
#
# Model names must match your configured models in default_models above.
priors:
  code:
    claude-sonnet-4.5: 0.92    # Best for code (SWE Bench leader)
    claude-opus-4.5: 0.91      # Premium code generation
    gpt-5.1: 0.88              # Strong coding performance
    gpt-5: 0.85                # Good balance
    o4-mini: 0.78              # Fast and decent
    gemini-2.5-pro: 0.82       # Strong alternative
    gemini-2.0-flash: 0.72     # Quick responses

  creative:
    claude-opus-4.5: 0.94      # Excellent creativity
    claude-sonnet-4.5: 0.90    # Strong creative writing
    gpt-5.1: 0.86              # Good creative output
    gpt-5: 0.82                # Solid creative tasks
    o4-mini: 0.74              # Acceptable for simple creative
    gemini-2.5-pro: 0.80       # Good creative alternative
    gemini-2.0-flash: 0.68     # Basic creative tasks

  analysis:
    claude-opus-4.5: 0.92      # Deep analytical ability
    gpt-5.1: 0.89              # Strong analysis
    claude-sonnet-4.5: 0.88    # Great for analysis
    gpt-5: 0.84                # Good for most analysis
    gemini-2.5-pro: 0.83       # Strong reasoning
    o4-mini: 0.76              # Lighter analysis
    gemini-2.0-flash: 0.70     # Quick analytical tasks

  simple_qa:
    o4-mini: 0.90              # Excellent for simple questions
    gemini-2.0-flash: 0.88     # Fast and accurate
    gpt-5: 0.85                # Reliable for QA
    claude-sonnet-4.5: 0.82    # Solid choice
    gemini-2.5-pro: 0.80       # Good but overkill
    claude-opus-4.5: 0.78      # Unnecessary power
    gpt-5.1: 0.76              # Premium for simple tasks

  general:
    gpt-5.1: 0.88              # Good all-rounder
    claude-opus-4.5: 0.87      # Premium quality
    claude-sonnet-4.5: 0.85    # Balanced performance
    gpt-5: 0.83                # Reliable
    gemini-2.5-pro: 0.82       # Strong alternative
    o4-mini: 0.78              # Cost-effective
    gemini-2.0-flash: 0.72     # Budget option

# Pricing Reference (Nov 2025)
# Used for cost calculation when database pricing is unavailable
pricing:
  # OpenAI
  o4-mini: {input: 1.10, output: 4.40}
  gpt-5.1: {input: 2.00, output: 8.00}
  gpt-5: {input: 2.00, output: 8.00}
  gpt-4o: {input: 2.50, output: 10.00}
  gpt-4o-mini: {input: 0.15, output: 0.60}
  
  # Anthropic
  claude-opus-4-5-20241124: {input: 5.00, output: 25.00}
  claude-sonnet-4-5-20241124: {input: 3.00, output: 15.00}
  claude-haiku-4-5-20241124: {input: 0.80, output: 4.00}
  claude-3-5-sonnet-20241022: {input: 3.00, output: 15.00}
  claude-3.5-sonnet: {input: 3.00, output: 15.00}
  claude-3-opus-20240229: {input: 15.00, output: 75.00}
  claude-3-sonnet-20240229: {input: 3.00, output: 15.00}
  claude-3-haiku-20240307: {input: 0.25, output: 1.25}
  
  # Google
  gemini-3.0-pro: {input: 1.25, output: 5.00}
  gemini-2.5-pro: {input: 1.25, output: 5.00}
  gemini-2.5-flash: {input: 0.075, output: 0.30}
  gemini-2.0-flash: {input: 0.075, output: 0.30}
  
  # Meta/Llama
  llama-4-maverick: {input: 0.20, output: 0.20}
  llama-4-scout: {input: 0.10, output: 0.10}
  
  # Mistral
  mistral-large-latest: {input: 2.00, output: 6.00}
  mistral-small-latest: {input: 0.20, output: 0.60}
